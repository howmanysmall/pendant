GITHUB_TOKEN=
NPM_TOKEN=

# OpenRouter (unified multi-model router)
OPEN_ROUTER_API_KEY=
# Optionally specify model if needed:
# OPEN_ROUTER_MODEL=

# Anthropic / Claude
ANTHROPIC_API_KEY=
# If using Claude Code CLI specifically:
CLAUDE_CODE_CLI_PATH=
CLAUDE_CODE_CLI_MODEL="claude-sonnet-4-20250514"

# Amazon Bedrock (AWS)
# LiteLLM expects `BEDROCK_MODEL`, AWS native expects AWS_REGION etc.
BEDROCK_MODEL=
AWS_DEFAULT_REGION="us-east-1"
AMAZON_BEDROCKS_REGION="us-east-1"
AMAZON_BEDROCKS_API_KEY=
AWS_PROFILE=
AMAZON_BEDROCKS_ACCESS_KEY_ID=
AMAZON_BEDROCKS_SECRET_ACCESS_KEY=
AMAZON_BEDROCKS_SESSION_TOKEN=

# Google Vertex AI / Gemini / PaLM
GOOGLE_MODEL=
GOOGLE_GEMINI_API_KEY=
GOOGLE_CLOUD_PROJECT=
VERTEXAI_MODEL=
VERTEX_LOCATION=

# OpenAI (or via Azure OpenAI â€“ configure separately if using Azure)
OPENAI_MODEL="gpt-4.1"
OPENAI_API_KEY=
# If using Azure OpenAI:
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_API_BASE=
AZURE_OPENAI_API_TYPE=
AZURE_OPENAI_API_VERSION=
AZURE_OPENAI_API_DEPLOYMENT_NAME=
AZURE_OPENAI_API_INSTANCE_NAME=

# DeepSeek
DEEPSEEK_API_KEY=
# Optionally default DeepSeek model in OpenRouter-compatible naming:
# DEEPSEEK_MODEL=

# Cohere
COHERE_API_KEY=
COHERE_MODEL=

# Mistral AI
MISTRAL_API_KEY=
MISTRAL_MODEL="codestral-2501"

# Groq
GROQ_API_KEY=
GROQ_MODEL=

# Yandex GPT
YANDEXGPT_API_KEY=
YANDEXGPT_MODEL=

# xAI (Grok)
XAI_API_KEY=
XAI_MODEL="grok-3-mini"

# Additional aggregator-friendly support (liteLLM, aider, etc.)
# For example for litellm:
# LITELLM_API_KEY=   (fallback)
# LITELLM_PROVIDER=openai or anthropic etc.
